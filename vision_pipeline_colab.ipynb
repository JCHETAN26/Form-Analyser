{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Fitness-AQA Vision Pipeline (YOLOv8-Pose Edition)\n",
        "\n",
        "## ‚öôÔ∏è INSTRUCTIONS:\n",
        "1. **Runtime ‚Üí Change runtime type ‚Üí GPU (T4)**\n",
        "2. Run **Step 1** (Installation). It will **automatically restart** the runtime.\n",
        "3. After the restart, start from **Step 2**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Step 1: Install Dependencies (AUTO-RESTART)\n",
        "\n",
        "**‚ö†Ô∏è This cell will restart the runtime!** After it finishes (you see 'Session crashed'), ignore the error and move to Step 2."
      ],
      "metadata": {
        "id": "install_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install YOLO and dependencies\n",
        "!pip install ultralytics scipy opencv-python matplotlib -q\n",
        "\n",
        "# 2. Downgrade numpy to fix binary incompatibility\n",
        "!pip install \"numpy<2.0.0\" --force-reinstall -q\n",
        "\n",
        "print(\"\\n‚úÖ Installation complete! RESTARTING RUNTIME to apply changes...\")\n",
        "\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 2: Verify Installation\n",
        "\n",
        "Run this after the auto-restart above."
      ],
      "metadata": {
        "id": "verify_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import scipy\n",
        "\n",
        "print(f\"‚úÖ YOLOv8 Version: {YOLO().version if hasattr(YOLO(), 'version') else 'Loaded'}\")\n",
        "print(f\"‚úÖ NumPy Version: {np.__version__}\")\n",
        "print(f\"‚úÖ GPU Available: {torch.cuda.is_available()}\")\n",
        "print(\"\\nüéâ Ready to process!\")"
      ],
      "metadata": {
        "id": "verify_install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì§ Step 3: Upload Your Video"
      ],
      "metadata": {
        "id": "upload_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    video_path = list(uploaded.keys())[0]\n",
        "    print(f\"‚úÖ Uploaded: {video_path}\")"
      ],
      "metadata": {
        "id": "upload_video"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Step 4: Define Processor"
      ],
      "metadata": {
        "id": "define_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "class YOLOPoseExtractor:\n",
        "    def __init__(self, model_variant='yolov8s-pose.pt', device='cuda'):\n",
        "        self.model = YOLO(model_variant)\n",
        "        self.device = device\n",
        "\n",
        "    def smooth_signal(self, keypoints, window_length=5, polyorder=2):\n",
        "        if len(keypoints) < window_length: return keypoints\n",
        "        smoothed = np.zeros_like(keypoints)\n",
        "        for i in range(keypoints.shape[1]):\n",
        "            smoothed[:, i, 0] = savgol_filter(keypoints[:, i, 0], window_length, polyorder)\n",
        "            smoothed[:, i, 1] = savgol_filter(keypoints[:, i, 1], window_length, polyorder)\n",
        "        return smoothed\n",
        "\n",
        "    def normalize_signal(self, keypoints):\n",
        "        normalized = np.zeros_like(keypoints)\n",
        "        for f in range(len(keypoints)):\n",
        "            frame_kps = keypoints[f]\n",
        "            mid_shoulder = (frame_kps[5] + frame_kps[6]) / 2\n",
        "            mid_hip = (frame_kps[11] + frame_kps[12]) / 2\n",
        "            torso_len = np.linalg.norm(mid_shoulder - mid_hip)\n",
        "            scale = 1.0 if torso_len < 1e-3 else 1.0 / torso_len\n",
        "            normalized[f] = (frame_kps - mid_hip) * scale\n",
        "        return normalized\n",
        "\n",
        "    def process_video(self, video_path):\n",
        "        results = self.model(video_path, stream=True, device=self.device, verbose=False)\n",
        "        raw_keypoints, scores = [], []\n",
        "        \n",
        "        for result in results:\n",
        "            if result.keypoints is not None and len(result.keypoints.data) > 0:\n",
        "                kp_data = result.keypoints.data[0].cpu().numpy()\n",
        "                raw_keypoints.append(kp_data[:, :2])\n",
        "                scores.append(result.keypoints.conf[0].cpu().numpy())\n",
        "            else:\n",
        "                raw_keypoints.append(np.zeros((17, 2)))\n",
        "                scores.append(np.zeros(17))\n",
        "\n",
        "        raw_keypoints = np.array(raw_keypoints)\n",
        "        smoothed = self.smooth_signal(raw_keypoints)\n",
        "        normalized = self.normalize_signal(smoothed)\n",
        "        \n",
        "        return {\n",
        "            \"video_id\": os.path.basename(video_path),\n",
        "            \"frame_count\": len(raw_keypoints),\n",
        "            \"raw_keypoints\": raw_keypoints.tolist(),\n",
        "            \"smoothed_keypoints\": smoothed.tolist(),\n",
        "            \"normalized_keypoints\": normalized.tolist(),\n",
        "            \"scores\": np.array(scores).tolist()\n",
        "        }\n",
        "\n",
        "print(\"‚úÖ Processor logic loaded!\")"
      ],
      "metadata": {
        "id": "logic_header"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Step 5: Run Extraction"
      ],
      "metadata": {
        "id": "run_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = YOLOPoseExtractor()\n",
        "result = extractor.process_video(video_path)\n",
        "with open('pullup_analysis.json', 'w') as f:\n",
        "    json.dump(result, f)\n",
        "print(f\"\\n‚úÖ Done! Saved to pullup_analysis.json\")"
      ],
      "metadata": {
        "id": "run_extraction"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Step 6: Download"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('pullup_analysis.json')\n",
        "print(\"‚úÖ Check your downloads folder!\")"
      ],
      "metadata": {
        "id": "download_json"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}

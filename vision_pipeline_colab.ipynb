{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üèãÔ∏è Fitness-AQA Vision Pipeline (Google Colab)\n",
        "\n",
        "This notebook extracts **2D pose keypoints** from exercise videos using **MMPose**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è IMPORTANT: Run cells in order!\n",
        "\n",
        "**Step 1** will install dependencies and **automatically restart the runtime**.  \n",
        "After restart, **manually run Steps 2-7**.\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Quick Start:\n",
        "1. Runtime ‚Üí Change runtime type ‚Üí **GPU (T4)**\n",
        "2. Run **Step 1** ‚Üí wait for auto-restart\n",
        "3. After restart, run **Steps 2-7**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ Step 1: Install Dependencies (AUTO-RESTART)\n",
        "\n",
        "**‚ö†Ô∏è This cell will restart the runtime automatically!**  \n",
        "After restart, continue with Step 2."
      ],
      "metadata": {
        "id": "install_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Install numpy first (before scipy to avoid ABI issues)\n",
        "!pip install \"numpy<2.0.0\" --force-reinstall -q\n",
        "\n",
        "# Upgrade installers\n",
        "!pip install --upgrade pip setuptools wheel -q\n",
        "\n",
        "# Install OpenMIM\n",
        "!pip install -U openmim -q\n",
        "\n",
        "# Install MMPose stack\n",
        "!mim install mmengine -q\n",
        "!mim install \"mmcv>=2.0.0,<2.2.0\" -q\n",
        "!mim install \"mmdet>=3.0.0\" -q\n",
        "!mim install \"mmpose>=1.0.0\" -q\n",
        "\n",
        "# Install scipy AFTER numpy is downgraded\n",
        "!pip install scipy opencv-python matplotlib -q\n",
        "\n",
        "print(\"\\n‚úÖ Installation complete! Restarting runtime...\")\n",
        "\n",
        "# Auto-restart to load new packages\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Step 2: Verify Installation\n",
        "\n",
        "**Run this after the runtime restarts to confirm everything installed correctly.**"
      ],
      "metadata": {
        "id": "verify_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import scipy\n",
        "import cv2\n",
        "from mmpose.apis import MMPoseInferencer\n",
        "\n",
        "print(f\"‚úÖ Python: {sys.version.split()[0]}\")\n",
        "print(f\"‚úÖ NumPy: {np.__version__}\")\n",
        "print(f\"‚úÖ SciPy: {scipy.__version__}\")\n",
        "print(f\"‚úÖ OpenCV: {cv2.__version__}\")\n",
        "print(f\"‚úÖ MMPose: Imported successfully\")\n",
        "print(\"\\nüéâ All dependencies loaded correctly!\")"
      ],
      "metadata": {
        "id": "verify_install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì§ Step 3: Upload Your Video"
      ],
      "metadata": {
        "id": "upload_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "video_path = list(uploaded.keys())[0]\n",
        "print(f\"‚úÖ Uploaded: {video_path}\")"
      ],
      "metadata": {
        "id": "upload_video"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Step 4: Define Pipeline"
      ],
      "metadata": {
        "id": "pipeline_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.signal import savgol_filter\n",
        "from mmpose.apis import MMPoseInferencer\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class PoseExtractor:\n",
        "    def __init__(self, mode='human', device='cuda'):\n",
        "        logger.info(f\"Loading MMPose (device={device})...\")\n",
        "        self.inferencer = MMPoseInferencer(mode, device=device)\n",
        "\n",
        "    def smooth_signal(self, keypoints, window_length=5, polyorder=2):\n",
        "        if len(keypoints) < window_length:\n",
        "            return keypoints\n",
        "        smoothed = np.zeros_like(keypoints)\n",
        "        for i in range(keypoints.shape[1]):\n",
        "            smoothed[:, i, 0] = savgol_filter(keypoints[:, i, 0], window_length, polyorder)\n",
        "            smoothed[:, i, 1] = savgol_filter(keypoints[:, i, 1], window_length, polyorder)\n",
        "        return smoothed\n",
        "\n",
        "    def normalize_signal(self, keypoints):\n",
        "        normalized = np.zeros_like(keypoints)\n",
        "        for f in range(len(keypoints)):\n",
        "            frame_kps = keypoints[f]\n",
        "            mid_shoulder = (frame_kps[5] + frame_kps[6]) / 2\n",
        "            mid_hip = (frame_kps[11] + frame_kps[12]) / 2\n",
        "            torso_len = np.linalg.norm(mid_shoulder - mid_hip)\n",
        "            scale = 1.0 if torso_len < 1e-3 else 1.0 / torso_len\n",
        "            normalized[f] = (frame_kps - mid_hip) * scale\n",
        "        return normalized\n",
        "\n",
        "    def process_video(self, video_path, output_path=None):\n",
        "        logger.info(f\"Processing: {video_path}\")\n",
        "        result_generator = self.inferencer(video_path, return_vis=False)\n",
        "        \n",
        "        raw_keypoints, scores = [], []\n",
        "        for result in result_generator:\n",
        "            preds = result['predictions']\n",
        "            if preds and len(preds) > 0:\n",
        "                raw_keypoints.append(preds[0]['keypoints'])\n",
        "                scores.append(preds[0]['keypoint_scores'])\n",
        "            else:\n",
        "                raw_keypoints.append(np.zeros((17, 2)))\n",
        "                scores.append(np.zeros(17))\n",
        "\n",
        "        raw_keypoints = np.array(raw_keypoints)\n",
        "        scores = np.array(scores)\n",
        "        \n",
        "        smoothed = self.smooth_signal(raw_keypoints)\n",
        "        normalized = self.normalize_signal(smoothed)\n",
        "        \n",
        "        data = {\n",
        "            \"video_id\": os.path.basename(video_path),\n",
        "            \"frame_count\": len(raw_keypoints),\n",
        "            \"raw_keypoints\": raw_keypoints.tolist(),\n",
        "            \"smoothed_keypoints\": smoothed.tolist(),\n",
        "            \"normalized_keypoints\": normalized.tolist(),\n",
        "            \"scores\": scores.tolist()\n",
        "        }\n",
        "        \n",
        "        if output_path:\n",
        "            with open(output_path, 'w') as f:\n",
        "                json.dump(data, f)\n",
        "            logger.info(f\"Saved to {output_path}\")\n",
        "        return data\n",
        "\n",
        "print(\"‚úÖ PoseExtractor ready!\")"
      ],
      "metadata": {
        "id": "define_pipeline"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Step 5: Process Video"
      ],
      "metadata": {
        "id": "run_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = PoseExtractor(mode='human', device='cuda')\n",
        "result = extractor.process_video(video_path, output_path='analysis.json')\n",
        "\n",
        "print(f\"\\n‚úÖ Processing complete!\")\n",
        "print(f\"üìä Frames: {result['frame_count']}\")\n",
        "print(f\"ÔøΩÔøΩ Output: analysis.json\")"
      ],
      "metadata": {
        "id": "run_pipeline"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 6: Visualize"
      ],
      "metadata": {
        "id": "viz_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if ret:\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    keypoints = np.array(result['smoothed_keypoints'][0])\n",
        "    \n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(frame_rgb)\n",
        "    plt.scatter(keypoints[:, 0], keypoints[:, 1], c='red', s=100, marker='o', edgecolors='white', linewidths=2)\n",
        "    \n",
        "    for i, (x, y) in enumerate(keypoints):\n",
        "        plt.text(x, y, str(i), color='yellow', fontsize=10, ha='center', va='center', weight='bold')\n",
        "    \n",
        "    plt.title(\"Detected Keypoints (Frame 0)\", fontsize=16)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot trajectory\n",
        "    left_wrist_idx = 9\n",
        "    raw_y = [kp[left_wrist_idx][1] for kp in result['raw_keypoints']]\n",
        "    smoothed_y = [kp[left_wrist_idx][1] for kp in result['smoothed_keypoints']]\n",
        "    \n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(raw_y, 'r-', alpha=0.4, linewidth=1, label='Raw (Jittery)')\n",
        "    plt.plot(smoothed_y, 'b-', linewidth=2.5, label='Smoothed')\n",
        "    plt.xlabel('Frame', fontsize=12)\n",
        "    plt.ylabel('Y Coordinate', fontsize=12)\n",
        "    plt.title('Left Wrist Movement - Smoothing Effect', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "visualize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Step 7: Download"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('analysis.json')\n",
        "print(\"‚úÖ Download started!\")"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Complete!\n",
        "\n",
        "**You now have `analysis.json` ready for Vishal!**\n",
        "\n",
        "**GitHub:** https://github.com/JCHETAN26/Form-Analyser  \n",
        "**Handoff Doc:** `HANDOFF_TO_VISHAL.md`\n"
      ],
      "metadata": {
        "id": "done"
      }
    }
  ]
}

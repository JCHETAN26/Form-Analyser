{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš€ Fitness-AQA Vision Pipeline (YOLOv8-Pose Edition)\n",
        "\n",
        "This version replaces MMPose with **YOLOv8**, making it much faster to install and run, while maintaining identical output for the modeling team.\n",
        "\n",
        "## ðŸ“‹ Features:\n",
        "- **Instant Setup:** No complex C++ dependencies.\n",
        "- **Identical Output:** 17 COCO keypoints (same as Vishal expected).\n",
        "- **Smooth Signals:** Includes Savitzky-Golay smoothing.\n",
        "- **Normalisation:** Includes scale-invariant coordinate scaling.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“¦ Step 1: Install Ultralytics\n",
        "\n",
        "Unlike MMPose, this only takes ~30 seconds and **doesn't** require a restart."
      ],
      "metadata": {
        "id": "install_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics scipy opencv-python matplotlib -q\n",
        "!pip install \"numpy<2.0.0\" -q\n",
        "\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(f\"âœ… YOLOv8 Installed!\")\n",
        "print(f\"âœ… GPU Available: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“¤ Step 2: Upload Your Video"
      ],
      "metadata": {
        "id": "upload_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    video_path = list(uploaded.keys())[0]\n",
        "    print(f\"âœ… Uploaded: {video_path}\")\n",
        "else:\n",
        "    print(\"âŒ No file uploaded.\")"
      ],
      "metadata": {
        "id": "upload_video"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”§ Step 3: Pipeline Logic"
      ],
      "metadata": {
        "id": "pipeline_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "class YOLOPoseExtractor:\n",
        "    def __init__(self, model_variant='yolov8s-pose.pt', device='cuda'):\n",
        "        self.model = YOLO(model_variant)\n",
        "        self.device = device\n",
        "\n",
        "    def smooth_signal(self, keypoints, window_length=5, polyorder=2):\n",
        "        if len(keypoints) < window_length: return keypoints\n",
        "        smoothed = np.zeros_like(keypoints)\n",
        "        for i in range(keypoints.shape[1]):\n",
        "            smoothed[:, i, 0] = savgol_filter(keypoints[:, i, 0], window_length, polyorder)\n",
        "            smoothed[:, i, 1] = savgol_filter(keypoints[:, i, 1], window_length, polyorder)\n",
        "        return smoothed\n",
        "\n",
        "    def normalize_signal(self, keypoints):\n",
        "        normalized = np.zeros_like(keypoints)\n",
        "        for f in range(len(keypoints)):\n",
        "            frame_kps = keypoints[f]\n",
        "            mid_shoulder = (frame_kps[5] + frame_kps[6]) / 2\n",
        "            mid_hip = (frame_kps[11] + frame_kps[12]) / 2\n",
        "            torso_len = np.linalg.norm(mid_shoulder - mid_hip)\n",
        "            scale = 1.0 if torso_len < 1e-3 else 1.0 / torso_len\n",
        "            normalized[f] = (frame_kps - mid_hip) * scale\n",
        "        return normalized\n",
        "\n",
        "    def process_video(self, video_path):\n",
        "        results = self.model(video_path, stream=True, device=self.device, verbose=False)\n",
        "        raw_keypoints, scores = [], []\n",
        "        \n",
        "        for result in results:\n",
        "            if result.keypoints is not None and len(result.keypoints.data) > 0:\n",
        "                kp_data = result.keypoints.data[0].cpu().numpy()\n",
        "                raw_keypoints.append(kp_data[:, :2])\n",
        "                scores.append(result.keypoints.conf[0].cpu().numpy())\n",
        "            else:\n",
        "                raw_keypoints.append(np.zeros((17, 2)))\n",
        "                scores.append(np.zeros(17))\n",
        "\n",
        "        raw_keypoints = np.array(raw_keypoints)\n",
        "        smoothed = self.smooth_signal(raw_keypoints)\n",
        "        normalized = self.normalize_signal(smoothed)\n",
        "        \n",
        "        return {\n",
        "            \"video_id\": os.path.basename(video_path),\n",
        "            \"frame_count\": len(raw_keypoints),\n",
        "            \"raw_keypoints\": raw_keypoints.tolist(),\n",
        "            \"smoothed_keypoints\": smoothed.tolist(),\n",
        "            \"normalized_keypoints\": normalized.tolist(),\n",
        "            \"scores\": np.array(scores).tolist()\n",
        "        }\n",
        "\n",
        "print(\"âœ… YOLO Logic Ready!\")"
      ],
      "metadata": {
        "id": "logic_header"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸš€ Step 4: Run Extraction"
      ],
      "metadata": {
        "id": "run_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor = YOLOPoseExtractor()\n",
        "result = extractor.process_video(video_path)\n",
        "\n",
        "output_file = 'pullup_analysis.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(result, f)\n",
        "\n",
        "print(f\"\\nâœ… Done! Processed {result['frame_count']} frames.\")\n",
        "print(f\"ðŸ’¾ Saved to: {output_file}\")"
      ],
      "metadata": {
        "id": "run_extraction"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’¾ Step 5: Download for Vishal"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('pullup_analysis.json')\n",
        "print(\"âœ… Download started! Send this to Vishal.\")"
      ],
      "metadata": {
        "id": "download"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
